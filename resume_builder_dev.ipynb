{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print wrapped text\n",
    "def print_text(text, width_char=100):\n",
    "    output = pprint.pprint(text, width=width_char)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(r'C:\\Users\\mnw47\\coding projects\\resume_builder\\audio_files\\2023_05_09_resume_points.m4a', 'rb')\n",
    "transcript = openai.Audio.transcribe('whisper-1', audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a journal, just spitballing on things I want to put on my resume for my current role at Newfront as a data scientist, where I've been for about almost a year now. So there are four bullet points that I want to write. The first bullet point is about the client dashboard. This is one of the two flagship technology products that Newfront creates, the Newfront engineering team creates, and it's customer-facing. And it's a platform that enables our insurance customers to manage everything in one place and in a modernized way. So for this product, I built a dashboard that measured... I built a dashboard that not only measured the usage of the product, but also illustrated how those laddered up to higher OKRs and goals like churn. This was a really hard problem because the software that Newfront creates is auxiliary to the main product, which is insurance. And so measuring the effect of the software that we build, which magnifies our main product, is very difficult because there is no direct relationship. So I thought through a product impact framework to ladder up the impact of projects like this to actual business outcomes, which was used in one-pagers for quarterly planning. So every engineering team used a template created by me where they had to specifically illustrate what sort of business impact their project had and how to go about measuring that and thinking about it. Not only that, the dashboard I built was also important because it illustrated that the product that we built was seeing very low adoption. Not many people were using it. And a lot of our customers weren't using it because they mainly cared that they have their insurance covered. And the proposition of just being able to manage their insurance in a technology portal when they had relationships with our sales and customer service team, for some of them, it wasn't a very attractive proposition. So the dashboard I built was used to quantitatively support decision-making that led us to pivot away from this customer-facing platform into AI products that rely on large language models. And a large part of our roadmap has been revamped with this understanding. The roadmap for the whole engineering team has been revamped from this quantitative understanding of the product adoption and the levers we could pull. The second bullet point I want to include is around leadership and being senior. And I want to say that I was the first the first data scientist of a team that has grown to a team that has grown to nine data scientists. You're the first and the most senior data scientist. Which required a couple of things. One, mentoring more junior data scientists. And also secondly, building team culture, which is really important when working fully remote, which is which Newfront is. Newfront is fully remote. And so setting up meetings to something called the quality crawl, where it's a regularly occurring biweekly meeting that's focused on cleaning up a specific tech debt across the entire team to team gains every week was a big part of my role. The third bullet point is a tool I built for our business insurance teams that primarily saved them a lot of time. And I want to quantify that by assuming that if we saved about if we saved if the EB insurance team has 50 people using this tool or even 100 people using this tool in a year, and each person is saved, each person has a couple of clients. So let's say, well, you can just do the math 300 clients, you know how many clients there are. So 300 clients, and they're able to produce a report, an hour, they're able to save an hour to produce a report for each client. That's 300 hours saved. So that equates to about to about. How much does that equate to? To about. Well, 300 hours, 300 hours saved. And just multiply that by some hourly rate, let's say 20, 30, $30. That's 300 hours, $30. 300 hours, $30 per hour. It's just $9000. Wait, really? Is that math right? 300 hours. OK, so there are 30, 300 clients. It saves everyone one, let's say even more, let's say, let's say it saves everyone three hours, each person three hours for every client. It actually makes sense. So 900 hours. And then let's say the average, average cost is $50. So $4500. Say $50,000 a year. Doesn't seem that impressive. 900, 900 hours, 900 hours, $50. $4500. Yeah, about $50,000 a year. Let's just say $100,000 a year. And but not only the saving time, but also it's probably about right. And you have prospects and stuff. Maybe you'll say $125,000 or something. But yeah, so you built this benchmarking tool. Let's say it saved $125,000 per year from time saved from manipulating things in Excel, from having a really brittle tech stack, and we created this tool in a low code app called Hex with Python and SQL. And we migrated, we migrated the prior tool from that was built with Excel macros to Hex. And we also, it was the back end was powered by dbt. And so we wrote, I had to write a lot, do a lot of dbt modeling, which connected to Salesforce, which was our source of truth. Another the last important part of this project is stakeholder management. Insurance is a notoriously archaic and stubborn industry. People have been doing this the same way for decades. And so being able to manage stakeholder expectations and build good build relationships where our insurance counterparts trust us, and we trust us, it was very, very important. Because again, we're building technology to enable our insurance partners, our technology only empowers only as helpful insofar as it empowers the insurance experts at our company. Lastly, lastly, well, let's just wrap up there because I haven't worked that much on this last project. So to summarize, three main points I want to add to my resume, product dashboard, the benchmarking tool, and leading data scientists.\n"
     ]
    }
   ],
   "source": [
    "text = transcript['text']\n",
    "print(transcript['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call OpenAI API\n",
    "def call_llm(prompt, model='gpt-3.5-turbo'):\n",
    "    messages=[{\n",
    "        'role': 'user'\n",
    "        , 'content': prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model\n",
    "        , max_tokens=1000\n",
    "        , temperature=0.0\n",
    "        , messages = messages)\n",
    "    \n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''Write resume bullet points that summarize the experience given.\n",
    "=====\n",
    "Here are examples of bullet points you should write:\n",
    "- Automated video review: ~$2M annual cost savings from deprecating manual safety review; Productionized a model that automatically hides videos with high content risk based on machine learning signals, leading a cross-functional team across product, engineering, and operations\n",
    "- Idea pin (new content format) safety: met OKR by reducing unsafe content on Pinterest by 10x; Conducted metric investigations and model performance analyses as the official metrics owner of idea pin safety, sizing opportunities and problems as well as fixing critical bugs\n",
    "- Fake following: identified 1% of user follows as bots to degame monetized engagement; Productionized a model that detected anomalous coordinated behavior among clusters of users using handcrafted features in SQL and Python\n",
    "- Launching spam rules: owned analysis to production end-to-end; Disabled ~300K policy violating users by shipping rules into production through events-based analyses of 100M+ events per day and hundreds of features\n",
    "- Payment network anticompetition defense: damages estimated at $1+B; Led a team of ten analysts to prove competition among the largest US payment cards firms, owning the accuracy of a ~200 page expert report\n",
    "- Department of Justice approval of health insurance merger: ~$50B valuation; Proved that the US health insurance industry would remain competitive post-merger of two Fortune 500 companies by analyzing win-loss Salesforce data using SQL and R\n",
    "=====\n",
    "Experience: {text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write resume bullet points that summarize the experience given.\n",
      "=====\n",
      "Here are examples of bullet points you should write:\n",
      "- Automated video review: ~$2M annual cost savings from deprecating manual safety review; Productionized a model that automatically hides videos with high content risk based on machine learning signals, leading a cross-functional team across product, engineering, and operations\n",
      "- Idea pin (new content format) safety: met OKR by reducing unsafe content on Pinterest by 10x; Conducted metric investigations and model performance analyses as the official metrics owner of idea pin safety, sizing opportunities and problems as well as fixing critical bugs\n",
      "- Fake following: identified 1% of user follows as bots to degame monetized engagement; Productionized a model that detected anomalous coordinated behavior among clusters of users using handcrafted features in SQL and Python\n",
      "- Launching spam rules: owned analysis to production end-to-end; Disabled ~300K policy violating users by shipping rules into production through events-based analyses of 100M+ events per day and hundreds of features\n",
      "- Payment network anticompetition defense: damages estimated at $1+B; Led a team of ten analysts to prove competition among the largest US payment cards firms, owning the accuracy of a ~200 page expert report\n",
      "- Department of Justice approval of health insurance merger: ~$50B valuation; Proved that the US health insurance industry would remain competitive post-merger of two Fortune 500 companies by analyzing win-loss Salesforce data using SQL and R\n",
      "=====\n",
      "Experience: This is a journal, just spitballing on things I want to put on my resume for my current role at Newfront as a data scientist, where I've been for about almost a year now. So there are four bullet points that I want to write. The first bullet point is about the client dashboard. This is one of the two flagship technology products that Newfront creates, the Newfront engineering team creates, and it's customer-facing. And it's a platform that enables our insurance customers to manage everything in one place and in a modernized way. So for this product, I built a dashboard that measured... I built a dashboard that not only measured the usage of the product, but also illustrated how those laddered up to higher OKRs and goals like churn. This was a really hard problem because the software that Newfront creates is auxiliary to the main product, which is insurance. And so measuring the effect of the software that we build, which magnifies our main product, is very difficult because there is no direct relationship. So I thought through a product impact framework to ladder up the impact of projects like this to actual business outcomes, which was used in one-pagers for quarterly planning. So every engineering team used a template created by me where they had to specifically illustrate what sort of business impact their project had and how to go about measuring that and thinking about it. Not only that, the dashboard I built was also important because it illustrated that the product that we built was seeing very low adoption. Not many people were using it. And a lot of our customers weren't using it because they mainly cared that they have their insurance covered. And the proposition of just being able to manage their insurance in a technology portal when they had relationships with our sales and customer service team, for some of them, it wasn't a very attractive proposition. So the dashboard I built was used to quantitatively support decision-making that led us to pivot away from this customer-facing platform into AI products that rely on large language models. And a large part of our roadmap has been revamped with this understanding. The roadmap for the whole engineering team has been revamped from this quantitative understanding of the product adoption and the levers we could pull. The second bullet point I want to include is around leadership and being senior. And I want to say that I was the first the first data scientist of a team that has grown to a team that has grown to nine data scientists. You're the first and the most senior data scientist. Which required a couple of things. One, mentoring more junior data scientists. And also secondly, building team culture, which is really important when working fully remote, which is which Newfront is. Newfront is fully remote. And so setting up meetings to something called the quality crawl, where it's a regularly occurring biweekly meeting that's focused on cleaning up a specific tech debt across the entire team to team gains every week was a big part of my role. The third bullet point is a tool I built for our business insurance teams that primarily saved them a lot of time. And I want to quantify that by assuming that if we saved about if we saved if the EB insurance team has 50 people using this tool or even 100 people using this tool in a year, and each person is saved, each person has a couple of clients. So let's say, well, you can just do the math 300 clients, you know how many clients there are. So 300 clients, and they're able to produce a report, an hour, they're able to save an hour to produce a report for each client. That's 300 hours saved. So that equates to about to about. How much does that equate to? To about. Well, 300 hours, 300 hours saved. And just multiply that by some hourly rate, let's say 20, 30, $30. That's 300 hours, $30. 300 hours, $30 per hour. It's just $9000. Wait, really? Is that math right? 300 hours. OK, so there are 30, 300 clients. It saves everyone one, let's say even more, let's say, let's say it saves everyone three hours, each person three hours for every client. It actually makes sense. So 900 hours. And then let's say the average, average cost is $50. So $4500. Say $50,000 a year. Doesn't seem that impressive. 900, 900 hours, 900 hours, $50. $4500. Yeah, about $50,000 a year. Let's just say $100,000 a year. And but not only the saving time, but also it's probably about right. And you have prospects and stuff. Maybe you'll say $125,000 or something. But yeah, so you built this benchmarking tool. Let's say it saved $125,000 per year from time saved from manipulating things in Excel, from having a really brittle tech stack, and we created this tool in a low code app called Hex with Python and SQL. And we migrated, we migrated the prior tool from that was built with Excel macros to Hex. And we also, it was the back end was powered by dbt. And so we wrote, I had to write a lot, do a lot of dbt modeling, which connected to Salesforce, which was our source of truth. Another the last important part of this project is stakeholder management. Insurance is a notoriously archaic and stubborn industry. People have been doing this the same way for decades. And so being able to manage stakeholder expectations and build good build relationships where our insurance counterparts trust us, and we trust us, it was very, very important. Because again, we're building technology to enable our insurance partners, our technology only empowers only as helpful insofar as it empowers the insurance experts at our company. Lastly, lastly, well, let's just wrap up there because I haven't worked that much on this last project. So to summarize, three main points I want to add to my resume, product dashboard, the benchmarking tool, and leading data scientists.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model `gpt4` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resume_points \u001b[39m=\u001b[39m call_llm(prompt, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt4\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m, in \u001b[0;36mcall_llm\u001b[1;34m(prompt, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_llm\u001b[39m(prompt, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      3\u001b[0m     messages\u001b[39m=\u001b[39m[{\n\u001b[0;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m         , \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: prompt}]\n\u001b[1;32m----> 6\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      7\u001b[0m         model\u001b[39m=\u001b[39;49mmodel\n\u001b[0;32m      8\u001b[0m         , max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m\n\u001b[0;32m      9\u001b[0m         , temperature\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m\n\u001b[0;32m     10\u001b[0m         , messages \u001b[39m=\u001b[39;49m messages)\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The model `gpt4` does not exist"
     ]
    }
   ],
   "source": [
    "resume_points = call_llm(prompt, model='gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"- Product impact framework: developed a framework to measure the impact of Newfront's \"\n",
      " 'customer-facing platform, resulting in a pivot towards AI products that rely on large language '\n",
      " 'models; Led the creation of a dashboard that measured usage and adoption of the platform, which '\n",
      " \"was used to support decision-making and revamp the engineering team's roadmap\\n\"\n",
      " '- Senior leadership: as the first and most senior data scientist, mentored junior data '\n",
      " 'scientists and built team culture in a fully remote environment; Established regular meetings '\n",
      " 'and initiatives, such as the quality crawl, to improve team efficiency and collaboration\\n'\n",
      " '- Benchmarking tool: built a low code app with Python and SQL that saved the EB insurance team '\n",
      " 'an estimated $125,000 per year in time saved from manipulating data in Excel; Migrated the prior '\n",
      " 'tool from Excel macros to Hex and connected it to Salesforce using dbt modeling, while managing '\n",
      " 'stakeholder expectations in a notoriously archaic industry')\n"
     ]
    }
   ],
   "source": [
    "print_text(resume_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
