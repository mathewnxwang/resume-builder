{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 44.4MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m audio_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmnw47\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcoding projects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mresume_builder\u001b[39m\u001b[39m\\\u001b[39m\u001b[39maudio_files\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2023_05_09_resume_points.m4a\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(audio_path)\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:233\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    230\u001b[0m mel_segment \u001b[39m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(dtype)\n\u001b[0;32m    232\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 233\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(mel_segment)\n\u001b[0;32m    234\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\transcribe.py:164\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[1;34m(segment)\u001b[0m\n\u001b[0;32m    161\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m options \u001b[39m=\u001b[39m DecodingOptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, temperature\u001b[39m=\u001b[39mt)\n\u001b[1;32m--> 164\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(segment, options)\n\u001b[0;32m    166\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    168\u001b[0m     compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    170\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:816\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    814\u001b[0m     options \u001b[39m=\u001b[39m replace(options, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 816\u001b[0m result \u001b[39m=\u001b[39m DecodingTask(model, options)\u001b[39m.\u001b[39;49mrun(mel)\n\u001b[0;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m single \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:729\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    726\u001b[0m tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mrepeat_interleave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(audio_features\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    728\u001b[0m \u001b[39m# call the main sampling loop\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_loop(audio_features, tokens)\n\u001b[0;32m    731\u001b[0m \u001b[39m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[0;32m    732\u001b[0m audio_features \u001b[39m=\u001b[39m audio_features[:: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group]\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:678\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[1;34m(self, audio_features, tokens)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    677\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_len):\n\u001b[1;32m--> 678\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference\u001b[39m.\u001b[39;49mlogits(tokens, audio_features)\n\u001b[0;32m    680\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    681\u001b[0m             i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mno_speech \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    682\u001b[0m         ):  \u001b[39m# save no_speech_probs\u001b[39;00m\n\u001b[0;32m    683\u001b[0m             probs_at_sot \u001b[39m=\u001b[39m logits[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msot_index]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\decoding.py:157\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[1;34m(self, tokens, audio_features)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m tokens\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_token_length:\n\u001b[0;32m    154\u001b[0m     \u001b[39m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     tokens \u001b[39m=\u001b[39m tokens[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mdecoder(tokens, audio_features, kv_cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkv_cache)\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mnw47\\anaconda3\\lib\\site-packages\\whisper\\model.py:216\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[1;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[0;32m    211\u001b[0m     x \u001b[39m=\u001b[39m block(x, xa, mask\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask, kv_cache\u001b[39m=\u001b[39mkv_cache)\n\u001b[0;32m    213\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln(x)\n\u001b[0;32m    214\u001b[0m logits \u001b[39m=\u001b[39m (\n\u001b[0;32m    215\u001b[0m     x \u001b[39m@\u001b[39;49m torch\u001b[39m.\u001b[39;49mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_embedding\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdtype), \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m--> 216\u001b[0m )\u001b[39m.\u001b[39;49mfloat()\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "audio_path = r'C:\\Users\\mnw47\\coding projects\\resume_builder\\audio_files\\2023_05_09_resume_points.m4a'\n",
    "result = model.transcribe(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = whisper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
